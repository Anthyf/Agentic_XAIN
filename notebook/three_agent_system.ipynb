{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0cc42f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a9fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c557d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yhe\\Desktop\\PHD\\Research\\25spring_Agentic_AI_project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import openai\n",
    "import asyncio \n",
    "import shap\n",
    "import pickle\n",
    "from autogen_core.models import AssistantMessage, FunctionExecutionResult, FunctionExecutionResultMessage, UserMessage\n",
    "from autogen_agentchat.agents import AssistantAgent, CodeExecutorAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(\"../SHAPnarrative-metrics\")\n",
    "sys.path.append(\"../script\")\n",
    "\n",
    "from shapnarrative_metrics.llm_tools import llm_wrappers\n",
    "from shapnarrative_metrics.misc_tools.manipulations import full_inversion, shap_permutation\n",
    "from shapnarrative_metrics.llm_tools.generation import GenerationModel\n",
    "from shapnarrative_metrics.llm_tools.extraction import ExtractionModel\n",
    "from FaithfulEvaluator import FaithfulEvaluatorAgent\n",
    "from Narrator import NarratorAgent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6334ed",
   "metadata": {},
   "source": [
    "#### API Key & dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7816f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([252, 236, 275, 148, 309,  33, 248, 150, 346, 246, 221, 261,   9, 204,\n",
      "       329, 207, 332,  59, 371,  11, 300, 299, 159, 280, 175, 374, 196, 189,\n",
      "       188, 211, 307, 284,  36,  72, 114, 274,  82, 345,  54, 385,  26, 190,\n",
      "       120, 212, 170,  24,  13,  95, 237, 285, 264,  20, 181, 107, 171, 223,\n",
      "       192,  42,  48,  15, 258, 228,  41,  31,  75, 102, 173, 373, 147,  79,\n",
      "       293,  91,  52, 179, 200, 199, 320, 375, 245],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "with open(\"../config/keys.yaml\") as f:\n",
    "    dict=yaml.safe_load(f)\n",
    "api_key = dict[\"API_keys\"][\"OpenAI\"]\n",
    "\n",
    "dataset_name=\"student\"\n",
    "\n",
    "with open(f'../data/{dataset_name}_dataset/dataset_info', 'rb') as f:\n",
    "   ds_info= pickle.load(f)\n",
    "\n",
    "with open(f'../data/{dataset_name}_dataset/RF.pkl', 'rb') as f:\n",
    "   trained_model=pickle.load(f)\n",
    "\n",
    "train=pd.read_parquet(f\"../data/{dataset_name}_dataset/train_cleaned.parquet\")\n",
    "test=pd.read_parquet(f\"../data/{dataset_name}_dataset/test_cleaned.parquet\")\n",
    "\n",
    "print(test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78bf358",
   "metadata": {},
   "source": [
    "#### Choose Data instance & Generate SHAP table, prompt and story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44493787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  feature_name  SHAP_value  feature_value  feature_average  \\\n",
      "0         Fedu   -0.038863              0         2.515823   \n",
      "1   Mjob_other   -0.038738              1         0.370253   \n",
      "2     failures    0.035703              0         0.360759   \n",
      "3     romantic   -0.033848              1         0.322785   \n",
      "\n",
      "                                        feature_desc  \n",
      "0  Father's education (0: none, 1: primary educat...  \n",
      "1        One-hot variable for mothers's job -- other  \n",
      "2        Number of past class failures (from 0 to 3)  \n",
      "3  Student is in a romantic relationship (0:no, 1...  \n"
     ]
    }
   ],
   "source": [
    "idx=171\n",
    "\n",
    "x=test[test.columns[0:-1]].loc[[idx]]\n",
    "y=test[test.columns[-1]].loc[[idx]]\n",
    "\n",
    "TEMPERATURE=0\n",
    "MANIP=False\n",
    "\n",
    "gpt = llm_wrappers.GptApi(api_key, model=\"gpt-4o\", system_role=\"You are a teacher that explains AI predictions.\", temperature=TEMPERATURE)\n",
    "generator=GenerationModel(ds_info=ds_info, llm=gpt)\n",
    "generator.gen_variables(trained_model,x,y,tree=True)\n",
    "#shap_df here is always the one without any manipulation\n",
    "shap_df=pd.DataFrame(generator.explanation_list[0].head(4))\n",
    "prompt = generator.generate_story_prompt(0,prompt_type=\"long\",manipulate=MANIP)\n",
    "print(shap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0688804",
   "metadata": {},
   "source": [
    "Load the defined system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93208963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SHAP table is normal (not manipulated)\n"
     ]
    }
   ],
   "source": [
    "from system_messages import (\n",
    "    system_message_narrator,\n",
    "    system_message_narrator_MANIP,\n",
    "    system_message_faithful_critic,\n",
    "    system_message_faithful_critic_MANIP,\n",
    "    system_message_coherence,\n",
    ")\n",
    "\n",
    "if MANIP:\n",
    "    narrator_sys_msg = system_message_narrator_MANIP\n",
    "    faithful_critic_sys_msg = system_message_faithful_critic_MANIP\n",
    "    coherence_sys_msg=system_message_coherence\n",
    "    print (\"The SHAP table is manipulated\")\n",
    "else:\n",
    "    narrator_sys_msg = system_message_narrator\n",
    "    faithful_critic_sys_msg = system_message_faithful_critic\n",
    "    coherence_sys_msg=system_message_coherence\n",
    "    print (\"The SHAP table is normal (not manipulated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94aa25",
   "metadata": {},
   "source": [
    " #### <span style=\"color: yellow \">First step:  coherence agent no function call\n",
    "   \n",
    "<span style=\"color: yellow \">1. coherenceagent only use plain language system message, without any functioncall or perplexity.\n",
    "<span style=\"color: yellow \">2. after reaching 100% faithulness, the coherenceagent start to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "\n",
      "\n",
      "        Your goal is to generate a textual explanation or narrative as to why an AI model made a certain prediction for one particular instance. \n",
      "        To do this, you will be provided with a dictionary that contains broad descriptions of the specific dataset, target variable, and the task the model was trained on.\n",
      "        Additionally, you will be provided with a dataframe that contains the names of all the features, their descriptions, their values, their average values and their SHAP values.\n",
      "        Finally you will get a single string describing the result of the prediction.\n",
      "\n",
      "        The goal of SHAP is to explain the prediction of an instance by computing the contribution of each feature to the prediction.\n",
      "        Each individual SHAP value is a measure of how much additional probability this feature adds or subtracts \n",
      "        in the predicted probability relative to the base level probability. \n",
      "        This relative nature of the SHAP values might have unexpected consequences that you are to take into account.\n",
      "        For example, features that should intuitively contribute in a positive way (and vice versa), \n",
      "        can still have negative SHAP values if their value is below an average in the dataset.\n",
      "\n",
      "        Here is the data:\n",
      "\n",
      "        Dataset description: The dataset contains information about students from two Portugese high schools and in particular their family situation and other habits,\n",
      "        Target description: The target variable represents the final year grade, transformed into whether the student passed (1) or not (0) at the end of the year,\n",
      "        Task description\": Predict whether a student will pass,\n",
      "        Feature table: feature_name  SHAP_value  feature_value  feature_average                                                                                                                       feature_desc\n",
      "        Fedu   -0.038863              0         2.515823 Father's education (0: none, 1: primary education (4th grade), 2: 5th to 9th grade, 3: secondary education or 4: higher education)\n",
      "  Mjob_other   -0.038738              1         0.370253                                                                                        One-hot variable for mothers's job -- other\n",
      "    failures    0.035703              0         0.360759                                                                                        Number of past class failures (from 0 to 3)\n",
      "    romantic   -0.033848              1         0.322785                                                                                Student is in a romantic relationship (0:no, 1:yes),\n",
      "        Result: The model predicted a probability of 65.00% for the target variable being 1,\n",
      "                    and therefore predicted the outcome 1.\n",
      "\n",
      "        The features in the \"Feature table\" above are already sorted by their absolute SHAP values to make it easier for you to locate the most important ones. \n",
      "        Always provide the probability of getting outcome 1, even if the predicted outcome is 0. \n",
      "\n",
      "        Please generate a fluent and cohesive narrative that explains the prediction made by the model. In your answer follow these rules.\n",
      "\n",
      "        Format related rules:\n",
      "\n",
      "        1) You can start the answer immediately with the explanation. \n",
      "        2) The answer should end with a single sentence summarizing and weighing the different factors. \n",
      "        3) Limit the entire answer to 10 sentences or fewer. \n",
      "        4) Only invoke the 4 most important features in the narrative. \n",
      "        5) Do not use tables or lists, or simply rattle through the features one by one. The goal is to have a narrative/story.\n",
      "\n",
      "        Content related rules:\n",
      "\n",
      "        1) Be clear about what the model actually predicted and how certain it was about that prediction. \n",
      "        2) Discuss how the features contributed to that prediction and be clear about whether a particular feature had a positive or negative contribution relative to the probability of getting outcome 1.\n",
      "           Make sure to clearly establish this the first time you refer to a feature.\n",
      "        3) Consider the relative magnitude of the absolute SHAP values of the features when referencing their relative importance.\n",
      "        4) The reader should be able to tell what the order of importance of the features is based on their absolute SHAP values. \n",
      "        5) You should provide a suggestion or interpretation as to why a feature contributed in a certain direction. Try to introduce external knowledge that you might have that is not in the SHAP table.  \n",
      "        6) If there is no simple explanation for the effect of a feature, try to consider the context of other features in the interpretation.\n",
      "        7) Do not use the SHAP numeric values in your answer.\n",
      "        8) You can use the feature values themselves in the explanation, as long as they are not categorical variables.\n",
      "        9) Do not use the comparison with the average for every single feature, and reserve it for features where it really clarifies the explanation.  \n",
      "        \n",
      "---------- narrator ----------\n",
      "Extracted story 1/1 with gpt-4o\n",
      "The model predicted a 65% probability that the student would pass, indicating a moderate level of confidence in this outcome.\n",
      "The father's education level, which was none, had the most significant negative impact on the prediction.\n",
      "This suggests that the lack of formal education from the father might have limited the student's access to educational support at home, thereby reducing the likelihood of passing.\n",
      "Similarly, the mother's job being categorized as \"other\" also negatively influenced the prediction.\n",
      "This could imply that the mother's job might not provide the stability or resources that could positively impact the student's academic performance.\n",
      "On the other hand, the student had no past class failures, which positively contributed to the prediction.\n",
      "This lack of failures indicates a consistent academic performance, enhancing the probability of passing.\n",
      "However, being in a romantic relationship slightly decreased the likelihood of passing, possibly due to the potential distraction from academic responsibilities.\n",
      "In summary, while the absence of past failures supported the prediction of passing, the educational and occupational background of the parents, along with the romantic relationship, introduced challenges that the model considered.\n",
      "---------- faithful_evaluator ----------\n",
      "Feature Mjob_other failed to extract value in ['value']. \n",
      "Feature romantic failed to extract value in ['value']. \n",
      "---------- faithful_critic ----------\n",
      "1. *Faithfulness Issues Identification*\n",
      "- You failed to extract feature value for Feature Mjob_other.\n",
      "- You failed to extract feature value for Feature romantic.\n",
      "\n",
      "2. *Conclusion*\n",
      "Revise ONLY and all those above mentioned issues in your narrative and respond with an improved and coherent narrative.\n",
      "---------- narrator ----------\n",
      "Extracted story 1/1 with gpt-4o\n",
      "The model predicted a 65% probability that the student would pass, indicating a moderate level of confidence in this outcome.\n",
      "The father's education level, which was none, had the most significant negative impact on the prediction.\n",
      "This suggests that the lack of formal education from the father might have limited the student's access to educational support at home, thereby reducing the likelihood of passing.\n",
      "Similarly, the mother's job being categorized as \"other\" also negatively influenced the prediction.\n",
      "This could imply that the mother's job might not provide the stability or resources that could positively impact the student's academic performance.\n",
      "On the other hand, the student had no past class failures, which positively contributed to the prediction.\n",
      "This lack of failures indicates a consistent academic performance, enhancing the probability of passing.\n",
      "However, being in a romantic relationship, indicated by a value of 1, slightly decreased the likelihood of passing, possibly due to the potential distraction from academic responsibilities.\n",
      "In summary, while the absence of past failures supported the prediction of passing, the educational and occupational background of the parents, along with the romantic relationship, introduced challenges that the model considered.\n",
      "---------- faithful_evaluator ----------\n",
      "Feature Mjob_other failed to extract value in ['value']. \n",
      "---------- faithful_critic ----------\n",
      "1. *Faithfulness Issues Identification*\n",
      "- You failed to extract feature value for Feature Mjob_other.\n",
      "\n",
      "2. *Conclusion*\n",
      "Revise ONLY and all those above mentioned issues in your narrative and respond with an improved and coherent narrative.\n",
      "---------- narrator ----------\n",
      "Extracted story 1/1 with gpt-4o\n",
      "The model predicted a 65% probability that the student would pass, indicating a moderate level of confidence in this outcome.\n",
      "The father's education level, which was none, had the most significant negative impact on the prediction.\n",
      "This suggests that the lack of formal education from the father might have limited the student's access to educational support at home, thereby reducing the likelihood of passing.\n",
      "Similarly, the mother's job being categorized as \"other,\" indicated by a value of 1, also negatively influenced the prediction.\n",
      "This could imply that the mother's job might not provide the stability or resources that could positively impact the student's academic performance.\n",
      "On the other hand, the student had no past class failures, which positively contributed to the prediction.\n",
      "This lack of failures indicates a consistent academic performance, enhancing the probability of passing.\n",
      "However, being in a romantic relationship, indicated by a value of 1, slightly decreased the likelihood of passing, possibly due to the potential distraction from academic responsibilities.\n",
      "In summary, while the absence of past failures supported the prediction of passing, the educational and occupational background of the parents, along with the romantic relationship, introduced challenges that the model considered.\n",
      "---------- faithful_evaluator ----------\n",
      "After checking, the narrative is 100% faithful to the SHAP table.\n",
      "---------- coherenceagent ----------\n",
      "COHERENCE ISSUES FOUND:\n",
      "\n",
      "1. **Order of Importance**: The narrative does not clearly establish the order of importance of the features based on their absolute SHAP values. The first-mentioned feature should be the most influential, and the fourth-mentioned feature should be the least influential. The narrative should emphasize this order of importance.\n",
      "\n",
      "2. **Explanation for Feature Contribution**: The narrative does not provide a clear explanation or interpretation for why the mother's job being categorized as \"other\" negatively influenced the prediction. It is important to provide a suggestion or interpretation for each feature's contribution direction.\n",
      "\n",
      "3. **Conjunction and Flow**: The narrative could benefit from improved conjunctions and flow between sentences to enhance coherence. For example, the transition between discussing the father's education and the mother's job could be smoother.\n",
      "\n",
      "Recommendations:\n",
      "- Clearly state the order of importance of the features based on their absolute SHAP values.\n",
      "- Provide a suggestion or interpretation for why the mother's job being \"other\" negatively influenced the prediction.\n",
      "- Improve the flow and conjunctions between sentences to enhance the narrative's coherence.\n",
      "---------- narrator ----------\n",
      "The model predicted a 65% probability that the student would pass, indicating a moderate level of confidence in this outcome.\n",
      "The most significant factor was the father's education level, which was none, negatively impacting the prediction.\n",
      "This suggests that the lack of formal education from the father might have limited the student's access to educational support at home, thereby reducing the likelihood of passing.\n",
      "Following this, the mother's job being categorized as \"other,\" indicated by a value of 1, also negatively influenced the prediction.\n",
      "This could imply that the mother's job might not provide the stability or resources that could positively impact the student's academic performance.\n",
      "Conversely, the student had no past class failures, which positively contributed to the prediction.\n",
      "This lack of failures indicates a consistent academic performance, enhancing the probability of passing.\n",
      "Lastly, being in a romantic relationship, indicated by a value of 1, slightly decreased the likelihood of passing, possibly due to the potential distraction from academic responsibilities.\n",
      "In summary, while the absence of past failures supported the prediction of passing, the educational and occupational background of the parents, along with the romantic relationship, introduced challenges that the model considered.\n",
      "---------- coherenceagent ----------\n",
      "COHERENCE ASSESSMENT: 100% coherent. No further improvements needed. TERMINATE.\n"
     ]
    }
   ],
   "source": [
    "# from autogen_agentchat.teams import SelectorGroupChat\n",
    "# from autogen_agentchat.messages import AgentEvent, ChatMessage\n",
    "# from selector_func import selector_func\n",
    "# import re\n",
    "\n",
    "# shap_df = shap_df\n",
    "\n",
    "# async def main() -> None:\n",
    "#     SEED = 42\n",
    "#     TEMPERATURE = 0\n",
    "\n",
    "#     # Initialize OpenAI client\n",
    "#     model_client = OpenAIChatCompletionClient(\n",
    "#         model=\"gpt-4o\",\n",
    "#         api_key=api_key,\n",
    "#         seed=SEED,\n",
    "#         temperature=TEMPERATURE\n",
    "#     )\n",
    "    \n",
    "#     # Create the narrator agent\n",
    "#     narrator = NarratorAgent(\n",
    "#         name=\"narrator\",\n",
    "#         system_message=narrator_sys_msg, \n",
    "#         model_client=model_client,\n",
    "#         reflect_on_tool_use=False,\n",
    "#     )\n",
    "    \n",
    "#     # Create the critic agent with advanced extraction capabilities\n",
    "#     faithful_evaluator = FaithfulEvaluatorAgent(\n",
    "#         name=\"faithful_evaluator\",\n",
    "#     )\n",
    "    \n",
    "#     # Set up the models for the critic - THIS IS IMPORTANT\n",
    "#     faithful_evaluator.set_models(\n",
    "#         extractor_class=ExtractionModel,\n",
    "#         generator_class=GenerationModel,\n",
    "#         ds_info=ds_info,\n",
    "#         llm=gpt\n",
    "#     )\n",
    "\n",
    "#     faithful_evaluator.default_shap_df = shap_df \n",
    "\n",
    "#     faithful_critic = AssistantAgent(\n",
    "#         name=\"faithful_critic\",\n",
    "#         system_message=faithful_critic_sys_msg,\n",
    "#         model_client=model_client,\n",
    "#         reflect_on_tool_use=False,\n",
    "#     )\n",
    "\n",
    "#     coherenceagent = AssistantAgent(\n",
    "#             name=\"coherenceagent\",\n",
    "#             system_message=coherence_sys_msg, \n",
    "#             model_client=model_client,\n",
    "#             reflect_on_tool_use=False,\n",
    "#         )\n",
    "\n",
    "#     # Create the group chat with custom processing\n",
    "#     termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(20)\n",
    "    \n",
    "#     group_chat = SelectorGroupChat(\n",
    "#         [narrator, faithful_evaluator, faithful_critic, coherenceagent],\n",
    "#         model_client=model_client,\n",
    "#         selector_func=selector_func,\n",
    "#         termination_condition=termination,\n",
    "#     )\n",
    "\n",
    "#     # Run the chat\n",
    "#     await Console(group_chat.run_stream(task=prompt))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "from autogen_agentchat.agents import ConversableAgent\n",
    "\n",
    "# The URL from ngrok that you'll get from running the Colab notebook\n",
    "PERPLEXITY_API_URL = \"https://xxxx-xx-xx-xxx-xxx.ngrok.io/perplexity\"\n",
    "\n",
    "async def get_perplexity(text):\n",
    "    \"\"\"Async function to get perplexity from our API\"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\n",
    "            PERPLEXITY_API_URL,\n",
    "            json={\"text\": text}\n",
    "        ) as response:\n",
    "            if response.status == 200:\n",
    "                result = await response.json()\n",
    "                return result[\"perplexity\"]\n",
    "            else:\n",
    "                error = await response.text()\n",
    "                raise Exception(f\"API Error: {error}\")\n",
    "\n",
    "# Define your CoherenceAgent that uses the perplexity API\n",
    "class CoherenceAgent(ConversableAgent):\n",
    "    async def analyze_coherence(self, narrative):\n",
    "        \"\"\"Analyze the coherence of a narrative using perplexity\"\"\"\n",
    "        try:\n",
    "            perplexity_score = await get_perplexity(narrative)\n",
    "            \n",
    "            # Create a coherence analysis based on perplexity\n",
    "            analysis = f\"Perplexity analysis: {perplexity_score:.2f}\\n\\n\"\n",
    "            \n",
    "            if perplexity_score < 50:\n",
    "                analysis += \"The narrative has excellent coherence! The flow is natural and easy to follow.\"\n",
    "            elif perplexity_score < 100:\n",
    "                analysis += \"The narrative has good coherence, but some minor improvements could be made.\"\n",
    "            elif perplexity_score < 200:\n",
    "                analysis += \"The narrative shows moderate coherence issues. Consider restructuring some sentences.\"\n",
    "            else:\n",
    "                analysis += \"The narrative has significant coherence problems. Consider simplifying complex parts.\"\n",
    "                \n",
    "            return analysis\n",
    "        except Exception as e:\n",
    "            return f\"Error calculating perplexity: {str(e)}\"\n",
    "    \n",
    "    async def _process_message(self, message):\n",
    "        if \"analyze_coherence\" in message.content:\n",
    "            # Extract narrative text from message\n",
    "            # This is simplified - you'll need to parse the actual message\n",
    "            narrative = message.content.replace(\"analyze_coherence:\", \"\").strip()\n",
    "            analysis = await self.analyze_coherence(narrative)\n",
    "            return analysis\n",
    "        return super()._process_message(message)\n",
    "\n",
    "# Define your agent system\n",
    "def setup_agents():\n",
    "    narrator = autogen.ConversableAgent(\n",
    "        name=\"narrator\",\n",
    "        system_message=\"You are a narrator who creates clear narratives.\"\n",
    "    )\n",
    "    \n",
    "    faithful_evaluator = autogen.ConversableAgent(\n",
    "        name=\"faithful_evaluator\",\n",
    "        system_message=\"You evaluate if narratives are faithful to data.\"\n",
    "    )\n",
    "    \n",
    "    faithful_critic = autogen.ConversableAgent(\n",
    "        name=\"faithful_critic\",\n",
    "        system_message=\"You critique narratives for faithfulness.\"\n",
    "    )\n",
    "    \n",
    "    coherence_agent = CoherenceAgent(\n",
    "        name=\"coherence_agent\",\n",
    "        system_message=\"You analyze the coherence of narratives.\"\n",
    "    )\n",
    "    \n",
    "    # Set up your groupchat with the agents\n",
    "    # ... existing setup code ...\n",
    "    \n",
    "    return narrator, faithful_evaluator, faithful_critic, coherence_agent\n",
    "\n",
    "# In your main function\n",
    "async def main():\n",
    "    # Set up agents\n",
    "    narrator, faithful_evaluator, faithful_critic, coherence_agent = setup_agents()\n",
    "    \n",
    "    # Test the perplexity calculation\n",
    "    test_narrative = \"This is a test narrative. It should be coherent and well-structured.\"\n",
    "    analysis = await coherence_agent.analyze_coherence(test_narrative)\n",
    "    print(analysis)\n",
    "    \n",
    "    # Rest of your agent interaction code\n",
    "    # ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
