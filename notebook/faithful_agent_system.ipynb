{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0cc42f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c557d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yhe\\Desktop\\PHD\\Research\\25spring_Agentic_AI_project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import openai\n",
    "import asyncio \n",
    "import shap\n",
    "import pickle\n",
    "from autogen_core.models import AssistantMessage, FunctionExecutionResult, FunctionExecutionResultMessage, UserMessage\n",
    "from autogen_agentchat.agents import AssistantAgent, CodeExecutorAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(\"../SHAPnarrative-metrics\")\n",
    "sys.path.append(\"../script\")\n",
    "\n",
    "from shapnarrative_metrics.llm_tools import llm_wrappers\n",
    "from shapnarrative_metrics.misc_tools.manipulations import full_inversion, shap_permutation\n",
    "from shapnarrative_metrics.llm_tools.generation import GenerationModel\n",
    "from shapnarrative_metrics.llm_tools.extraction import ExtractionModel\n",
    "from ExtractorCritic import ExtractorCriticAgent\n",
    "from Narrator import NarratorAgent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6334ed",
   "metadata": {},
   "source": [
    "#### API Key & dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7816f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([252, 236, 275, 148, 309,  33, 248, 150, 346, 246, 221, 261,   9, 204,\n",
      "       329, 207, 332,  59, 371,  11, 300, 299, 159, 280, 175, 374, 196, 189,\n",
      "       188, 211, 307, 284,  36,  72, 114, 274,  82, 345,  54, 385,  26, 190,\n",
      "       120, 212, 170,  24,  13,  95, 237, 285, 264,  20, 181, 107, 171, 223,\n",
      "       192,  42,  48,  15, 258, 228,  41,  31,  75, 102, 173, 373, 147,  79,\n",
      "       293,  91,  52, 179, 200, 199, 320, 375, 245],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "with open(\"../config/keys.yaml\") as f:\n",
    "    dict=yaml.safe_load(f)\n",
    "api_key = dict[\"API_keys\"][\"OpenAI\"]\n",
    "\n",
    "dataset_name=\"student\"\n",
    "\n",
    "with open(f'../data/{dataset_name}_dataset/dataset_info', 'rb') as f:\n",
    "   ds_info= pickle.load(f)\n",
    "\n",
    "with open(f'../data/{dataset_name}_dataset/RF.pkl', 'rb') as f:\n",
    "   trained_model=pickle.load(f)\n",
    "\n",
    "train=pd.read_parquet(f\"../data/{dataset_name}_dataset/train_cleaned.parquet\")\n",
    "test=pd.read_parquet(f\"../data/{dataset_name}_dataset/test_cleaned.parquet\")\n",
    "\n",
    "print(test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78bf358",
   "metadata": {},
   "source": [
    "#### Choose Data instance & Generate SHAP table, prompt and story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44493787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  feature_name  SHAP_value  feature_value  feature_average  \\\n",
      "0     freetime   -0.052233              1         3.243671   \n",
      "1     failures    0.026886              0         0.360759   \n",
      "2   Mjob_other    0.025752              0         0.370253   \n",
      "3        goout    0.025017              2         3.098101   \n",
      "\n",
      "                                        feature_desc  \n",
      "0  Free time after school (from 1 - very low to 5...  \n",
      "1        Number of past class failures (from 0 to 3)  \n",
      "2        One-hot variable for mothers's job -- other  \n",
      "3  Going out with friends (from 1 - very low to 5...  \n"
     ]
    }
   ],
   "source": [
    "idx=293\n",
    "\n",
    "x=test[test.columns[0:-1]].loc[[idx]]\n",
    "y=test[test.columns[-1]].loc[[idx]]\n",
    "\n",
    "TEMPERATURE=0\n",
    "MANIP=True\n",
    "\n",
    "gpt = llm_wrappers.GptApi(api_key, model=\"gpt-4o\", system_role=\"You are a teacher that explains AI predictions.\", temperature=TEMPERATURE)\n",
    "generator=GenerationModel(ds_info=ds_info, llm=gpt)\n",
    "generator.gen_variables(trained_model,x,y,tree=True)\n",
    "#shap_df here is always the one without any manipulation\n",
    "shap_df=pd.DataFrame(generator.explanation_list[0].head(4))\n",
    "prompt = generator.generate_story_prompt(0,prompt_type=\"long\",manipulate=MANIP)\n",
    "print(shap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be34f7a7",
   "metadata": {},
   "source": [
    "## Solution: Three-agent system: ExtractorCritic and FaithfulCritic \n",
    "FaithfulCritic summarizes ExtractorCritic's feedback and clearly communicates how the narrative should be revised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0688804",
   "metadata": {},
   "source": [
    "Load the defined system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93208963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SHAP table is manipulated\n"
     ]
    }
   ],
   "source": [
    "from system_messages import (\n",
    "    system_message_narrator,\n",
    "    system_message_narrator_MANIP,\n",
    "    system_message_faithfulcritic,\n",
    "    system_message_faithfulcritic_MANIP,\n",
    "    system_message_coherence,\n",
    ")\n",
    "\n",
    "if MANIP:\n",
    "    narrator_sys_msg = system_message_narrator_MANIP\n",
    "    faithfulcritic_sys_msg = system_message_faithfulcritic_MANIP\n",
    "    coherence_sys_msg=system_message_coherence\n",
    "    print (\"The SHAP table is manipulated\")\n",
    "else:\n",
    "    narrator_sys_msg = system_message_narrator\n",
    "    faithfulcritic_sys_msg = system_message_faithfulcritic\n",
    "    coherence_sys_msg=system_message_coherence\n",
    "    print (\"The SHAP table is normal (not manipulated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a7e34",
   "metadata": {},
   "source": [
    "## Three agent system (with extractor and faithful critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = shap_df\n",
    "\n",
    "async def main() -> None:\n",
    "    SEED = 42\n",
    "    TEMPERATURE = 0\n",
    "\n",
    "    # Initialize OpenAI client\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "        api_key=api_key,\n",
    "        seed=SEED,\n",
    "        temperature=TEMPERATURE\n",
    "    )\n",
    "    \n",
    "    # Create the narrator agent\n",
    "    narrator = NarratorAgent(\n",
    "        name=\"narrator\",\n",
    "        system_message=narrator_sys_msg, \n",
    "        model_client=model_client,\n",
    "        reflect_on_tool_use=False,\n",
    "    )\n",
    "    \n",
    "    # Create the critic agent with advanced extraction capabilities\n",
    "    extractorcritic = ExtractorCriticAgent(\n",
    "        name=\"extractorcritic\",\n",
    "    )\n",
    "    \n",
    "    # Set up the models for the critic - THIS IS IMPORTANT\n",
    "    extractorcritic.set_models(\n",
    "        extractor_class=ExtractionModel,\n",
    "        generator_class=GenerationModel,\n",
    "        ds_info=ds_info,\n",
    "        llm=gpt\n",
    "    )\n",
    "\n",
    "    extractorcritic.default_shap_df = shap_df \n",
    "\n",
    "    faithfulcritic = AssistantAgent(\n",
    "        name=\"faithfulcritic\",\n",
    "        system_message=faithfulcritic_sys_msg,\n",
    "        model_client=model_client,\n",
    "        reflect_on_tool_use=False,\n",
    "    )\n",
    "\n",
    "    # Create the group chat with custom processing\n",
    "    termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(13)\n",
    "    \n",
    "    group_chat = RoundRobinGroupChat(\n",
    "        [narrator, extractorcritic, faithfulcritic],\n",
    "        termination_condition=termination\n",
    "    )\n",
    "    \n",
    "    # Run the chat\n",
    "    stream = group_chat.run_stream(task=prompt)\n",
    "    \n",
    "    await Console(stream)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
